{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":68479,"databundleVersionId":10950255,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Data Understanding ","metadata":{}},{"cell_type":"markdown","source":"The attributes related with eating habits are: Frequent consumption of high caloric food (FAVC), Frequency of consumption of vegetables (FCVC), Number of main meals (NCP), Consumption of food between meals (CAEC), Consumption of water daily (CH20), and Consumption of alcohol (CALC). \n\nThe attributes related with the physical condition are: Calories consumption monitoring (SCC), Physical activity frequency (FAF), Time using technology devices (TUE), Transportation used (MTRANS)\n\nVariables obtained :\nFamily history with overweight, Gender, Age, Height and Weight\n\nNObesity values are:\n\n•Underweight Less than 18.5\n\n•Normal 18.5 to 24.9\n\n•Overweight 25.0 to 29.9\n\n•Obesity I 30.0 to 34.9\n\n•Obesity II 35.0 to 39.9\n\n•Obesity III Higher than 40\n\n\n\nEvaluation\nSubmissions are evaluated using the accuracy score.\n\nSubmission File\nFor each id row in the test set, you must predict the class value of the target, NObeyesdad. The file should contain a header and have the following format:\n\nid,NObeyesdad\n20758,Normal_Weight\n20759,Normal_Weight\n20760,Normal_Weight\netc.","metadata":{}},{"cell_type":"markdown","source":"# 2. Import packages and data ","metadata":{}},{"cell_type":"code","source":"!pip install ISLP","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom IPython.display import display\nfrom ISLP import confusion_table\nfrom ISLP.models import (ModelSpec as MS, summarize, contrast)\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, label_binarize\n\nimport warnings\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(\"ignore\", category=DataConversionWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:08.052442Z","iopub.execute_input":"2025-09-03T03:03:08.052829Z","iopub.status.idle":"2025-09-03T03:03:11.080772Z","shell.execute_reply.started":"2025-09-03T03:03:08.052797Z","shell.execute_reply":"2025-09-03T03:03:11.078503Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/988199628.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mISLP\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mISLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModelSpec\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ISLP'"],"ename":"ModuleNotFoundError","evalue":"No module named 'ISLP'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# get directory for data \nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.081694Z","iopub.status.idle":"2025-09-03T03:03:11.082020Z","shell.execute_reply.started":"2025-09-03T03:03:11.081870Z","shell.execute_reply":"2025-09-03T03:03:11.081884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/playground-series-s4e2/test.csv')\ntrain = pd.read_csv('/kaggle/input/playground-series-s4e2/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.082970Z","iopub.status.idle":"2025-09-03T03:03:11.083304Z","shell.execute_reply.started":"2025-09-03T03:03:11.083116Z","shell.execute_reply":"2025-09-03T03:03:11.083132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"Train shape:\", train.shape)\nprint(\"=========================================\")\nprint(\"Test  shape:\", test.shape)\nprint(\"=========================================\")\nprint(\"\\nTrain info:\")\ntrain.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.085231Z","iopub.status.idle":"2025-09-03T03:03:11.085667Z","shell.execute_reply.started":"2025-09-03T03:03:11.085452Z","shell.execute_reply":"2025-09-03T03:03:11.085491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train. head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.086637Z","iopub.status.idle":"2025-09-03T03:03:11.087018Z","shell.execute_reply.started":"2025-09-03T03:03:11.086838Z","shell.execute_reply":"2025-09-03T03:03:11.086853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# set variable types and check for missing values and 0s \ncat_vars = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n\nnum_vars = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n\ntarget = ['NObeyesdad']\n\ntrain[cat_vars] = train[cat_vars].astype('category')\ntest[cat_vars] = test[cat_vars].astype('category')\ntrain[target] = train[target].astype('category')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.088643Z","iopub.status.idle":"2025-09-03T03:03:11.089038Z","shell.execute_reply.started":"2025-09-03T03:03:11.088832Z","shell.execute_reply":"2025-09-03T03:03:11.088851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# calulate BMI to add to varibles \n\nfor df in (train, test):\n    df['BMI'] = df['Weight'] / (df['Height']**2)\n\n# Register BMI as numeric\nif 'BMI' not in num_vars:\n    num_vars.append('BMI')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.089879Z","iopub.status.idle":"2025-09-03T03:03:11.090135Z","shell.execute_reply.started":"2025-09-03T03:03:11.090022Z","shell.execute_reply":"2025-09-03T03:03:11.090033Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Start EDA ","metadata":{}},{"cell_type":"code","source":"# Numeric summary\nprint(\"\\nNumeric summary (train):\")\nprint(train[num_vars].describe())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.090684Z","iopub.status.idle":"2025-09-03T03:03:11.091030Z","shell.execute_reply.started":"2025-09-03T03:03:11.090869Z","shell.execute_reply":"2025-09-03T03:03:11.090887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Missingness checks\nprint(\"\\nMissing values per column (train):\")\nprint(train.isna().sum())\nprint(\"\\nMissing values per column (test):\")\nprint(test.isna().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.092840Z","iopub.status.idle":"2025-09-03T03:03:11.093212Z","shell.execute_reply.started":"2025-09-03T03:03:11.093032Z","shell.execute_reply":"2025-09-03T03:03:11.093049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Target distribution\nprint(\"\\nTarget distribution (counts):\")\nprint(train[target].value_counts())\nprint(\"\\nTarget distribution (proportions):\")\nprint(train[target].value_counts(normalize=True))\n\nprint(\"====================================================\")\n# Bar chart of target distribution\nplt.figure(figsize=(10,4))\n(train[target].value_counts(normalize=True)\n     .sort_index()\n     .plot(kind='bar'))\nplt.title(\"Class Proportions: NObeyesdad\")\nplt.ylabel(\"Proportion\")\nplt.xlabel(\"Class\")\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.094491Z","iopub.status.idle":"2025-09-03T03:03:11.094840Z","shell.execute_reply.started":"2025-09-03T03:03:11.094666Z","shell.execute_reply":"2025-09-03T03:03:11.094682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlations among numeric features\ncorr = train[num_vars].corr()\nplt.figure(figsize=(7,6))\nim = plt.imshow(corr, interpolation='nearest')\nplt.colorbar(im, fraction=0.046, pad=0.04)\nplt.xticks(range(len(num_vars)), num_vars, rotation=45, ha='right')\nplt.yticks(range(len(num_vars)), num_vars)\nplt.title(\"Correlation Heatmap (Numeric Features)\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.096270Z","iopub.status.idle":"2025-09-03T03:03:11.096603Z","shell.execute_reply.started":"2025-09-03T03:03:11.096425Z","shell.execute_reply":"2025-09-03T03:03:11.096437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Class-wise numeric means\ngroup_means = train.groupby(target)[num_vars].mean()\nprint(\"\\nClass-wise means of numeric features:\")\ndisplay(group_means)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.097560Z","iopub.status.idle":"2025-09-03T03:03:11.097839Z","shell.execute_reply.started":"2025-09-03T03:03:11.097706Z","shell.execute_reply":"2025-09-03T03:03:11.097716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Univariate histograms\nfig, axes = plt.subplots(3, 3, figsize=(14,10))\naxes = axes.ravel()\nfor i, col in enumerate(num_vars):\n    axes[i].hist(train[col].values, bins=30)\n    axes[i].set_title(col)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.098987Z","iopub.status.idle":"2025-09-03T03:03:11.099315Z","shell.execute_reply.started":"2025-09-03T03:03:11.099150Z","shell.execute_reply":"2025-09-03T03:03:11.099165Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Design Matrices ","metadata":{}},{"cell_type":"code","source":"# Build explicit contrasts for each categorical (treatment coding)\nencoded_cats = [contrast(v, 'drop') for v in cat_vars]\n\n# 3) Assemble ModelSpec terms (categorical contrasts + numeric features)\nall_terms = encoded_cats + num_vars\n\n# 4) Fit the design on TRAIN+TEST predictors to capture ALL category levels\ndesign = MS(all_terms, intercept=True)\npredictor_cols = cat_vars + num_vars\ncombined_predictors = pd.concat([train[predictor_cols], test[predictor_cols]], ignore_index=True)\n_ = design.fit(combined_predictors)\n\n# 5) Transform TRAIN and TEST -> fully numeric design matrices\nX_full      = design.transform(train[predictor_cols]) \nX_test_full = design.transform(test[predictor_cols])\ny_full      = train[target]\n\n# 6) Train/Valid split (stratified) using row indices so matrices stay aligned\nfrom sklearn.model_selection import train_test_split\nidx_train, idx_valid = train_test_split(\n    np.arange(train.shape[0]),\n    test_size=0.20,\n    stratify=y_full,\n    random_state=42\n)\nX_train = X_full.iloc[idx_train].copy()\nX_valid = X_full.iloc[idx_valid].copy()\ny_train = y_full.iloc[idx_train].copy()\ny_valid = y_full.iloc[idx_valid].copy()\n\n# 7) Drop ISLP 'intercept' \nif 'intercept' in X_train.columns:\n    X_train_no_int = X_train.drop(columns=['intercept'])\n    X_valid_no_int = X_valid.drop(columns=['intercept'])\n    X_full_no_int  = X_full.drop(columns=['intercept'])\n    X_test_no_int  = X_test_full.drop(columns=['intercept'])\nelse:\n    X_train_no_int = X_train\n    X_valid_no_int = X_valid\n    X_full_no_int  = X_full\n    X_test_no_int  = X_test_full\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.100528Z","iopub.status.idle":"2025-09-03T03:03:11.100785Z","shell.execute_reply.started":"2025-09-03T03:03:11.100665Z","shell.execute_reply":"2025-09-03T03:03:11.100675Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Models ","metadata":{}},{"cell_type":"code","source":"# standardize for Logit and SVM \nlogit_clf = Pipeline(steps=[\n    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n    ('model', LogisticRegression(\n        multi_class='multinomial', solver='lbfgs', max_iter=2000, n_jobs=None, random_state=42\n    ))\n])\n\nlda_clf = LDA(store_covariance=True, solver='svd')  \nnb_clf  = GaussianNB()                             \nsvm_clf = Pipeline(steps=[\n    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n    ('model', SVC(kernel='rbf', C=3.0, gamma='scale', probability=True, random_state=42))\n])\n\nmodels = {\n    'logit_multinomial': logit_clf,\n    'lda': lda_clf,\n    'naive_bayes': nb_clf,\n    'svm_rbf': svm_clf\n}\n\n# Add shrinkage LDA variant (uses Ledoit–Wolf)\nmodels['lda_shrink'] = LDA(solver='lsqr', shrinkage='auto')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.102370Z","iopub.status.idle":"2025-09-03T03:03:11.102743Z","shell.execute_reply.started":"2025-09-03T03:03:11.102569Z","shell.execute_reply":"2025-09-03T03:03:11.102585Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. View results ","metadata":{}},{"cell_type":"code","source":"results = []\n\ndef get_estimator(m):\n    # works for Pipeline or bare estimator\n    return m.named_steps['model'] if hasattr(m, 'named_steps') else m\n\n# ensure 1D string labels \ny_train_1d = y_train.astype(str).to_numpy()\ny_valid_1d = y_valid.astype(str).to_numpy()\ny_full_1d  = y_full.astype(str).to_numpy()\n\nfor name, mdl in models.items():\n    print(f\"\\n=== Fitting: {name} ===\")\n\n    # Fit\n    mdl.fit(X_train_no_int, y_train_1d)\n\n    # Predict labels\n    y_pred = mdl.predict(X_valid_no_int)\n    acc = accuracy_score(y_valid_1d, y_pred)\n    print(f\"Validation Accuracy: {acc:.4f}\")\n\n    # ISLP confusion table (rows=Predicted, cols=Truth)\n    print(\"\\nConfusion Table (rows=Predicted, cols=Truth):\")\n    C = confusion_table(y_pred, y_valid_1d)\n    display(C)\n\n    # Classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_valid_1d, y_pred, digits=3))\n\n    # Macro AUC (One-vs-Rest)\n    macro_auc = np.nan\n    est = get_estimator(mdl)\n    if hasattr(est, \"predict_proba\"):\n        y_proba = mdl.predict_proba(X_valid_no_int)\n        classes_est = np.array([str(c) for c in est.classes_])  # order matches proba columns\n        y_valid_bin = label_binarize(y_valid_1d, classes=classes_est)\n        try:\n            macro_auc = roc_auc_score(y_valid_bin, y_proba, average='macro')\n            print(f\"Macro ROC AUC (OvR): {macro_auc:.4f}\")\n        except Exception as e:\n            print(\"AUC not computed:\", e)\n\n    # 5-fold CV accuracy\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    cv_scores = cross_val_score(mdl, X_full_no_int, y_full_1d, cv=cv, scoring='accuracy')\n    print(f\"5-Fold CV Accuracy: mean={cv_scores.mean():.4f}, std={cv_scores.std():.4f}\")\n\n    results.append({\n        'model': name,\n        'val_accuracy': acc,\n        'cv_mean_acc': cv_scores.mean(),\n        'cv_std': cv_scores.std(),\n        'macro_auc_ovr': macro_auc\n    })\n\nresults_df = pd.DataFrame(results).sort_values(by='val_accuracy', ascending=False)\nprint(\"\\n=== Model Comparison (Validation) ===\")\ndisplay(results_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.105050Z","iopub.status.idle":"2025-09-03T03:03:11.105579Z","shell.execute_reply.started":"2025-09-03T03:03:11.105332Z","shell.execute_reply":"2025-09-03T03:03:11.105351Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Conduct compact SVM hyperparameter sweep to increase acuracy of SVM model","metadata":{}},{"cell_type":"code","source":"# Compact SVM (RBF) hyperparameter sweep\ndef to_1d_str(y):\n    # If DataFrame, require a single column then squeeze\n    if isinstance(y, pd.DataFrame):\n        if y.shape[1] != 1:\n            raise ValueError(f\"y has shape {y.shape}; expected a single column.\")\n        y = y.iloc[:, 0]\n    # Convert to numpy and flatten if needed\n    arr = y.to_numpy() if isinstance(y, pd.Series) else np.asarray(y)\n    if arr.ndim == 2:\n        if arr.shape[1] == 1:\n            arr = arr[:, 0]\n        else:\n            arr = arr.reshape(-1)\n    return arr.astype(str)\n\ny_train_1d = to_1d_str(y_train)\ny_valid_1d = to_1d_str(y_valid)\ny_full_1d  = to_1d_str(y_full)\n# Pipeline: scale -> SVC(probabilities enabled)\nsvm_pipe = Pipeline(steps=[\n    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n    ('model', SVC(kernel='rbf', probability=True, random_state=42))\n])\n\n# Compact grid\nparam_grid = {\n    'model__C':     [0.5, 1, 2, 3, 5],\n    'model__gamma': ['scale', 0.03, 0.1, 0.3]\n}\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nsvm_gs = GridSearchCV(\n    estimator=svm_pipe,\n    param_grid=param_grid,\n    scoring='accuracy',\n    cv=cv,\n    n_jobs=-1,\n    refit=True,\n    verbose=1\n)\n\n# Fit on training split\nsvm_gs.fit(X_train_no_int, y_train_1d)\nprint(\"Best params:\", svm_gs.best_params_)\nprint(\"Best CV mean accuracy:\", svm_gs.best_score_)\n\n# Validate\ny_pred = svm_gs.predict(X_valid_no_int)\nval_acc = accuracy_score(y_valid_1d, y_pred)\nprint(f\"\\nValidation Accuracy (tuned SVM): {val_acc:.4f}\")\n\nprint(\"\\nConfusion Table (rows=Predicted, cols=Truth):\")\ndisplay(confusion_table(y_pred, y_valid_1d))\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_valid_1d, y_pred, digits=3))\n\n# Macro AUC (OvR)\nest = svm_gs.best_estimator_.named_steps['model']\nclasses_est = np.array([str(c) for c in est.classes_])\ny_proba = svm_gs.predict_proba(X_valid_no_int)\ny_valid_bin = label_binarize(y_valid_1d, classes=classes_est)\nmacro_auc = roc_auc_score(y_valid_bin, y_proba, average='macro')\nprint(f\"Macro ROC AUC (OvR): {macro_auc:.4f}\")\n\n# CV results heatmap (mean accuracy)\ncvres = pd.DataFrame(svm_gs.cv_results_)\nheat = cvres.pivot(index='param_model__C', columns='param_model__gamma', values='mean_test_score')\nplt.figure(figsize=(6,4))\nplt.imshow(heat.values, aspect='auto')\nplt.xticks(range(heat.shape[1]), heat.columns.astype(str), rotation=45, ha='right')\nplt.yticks(range(heat.shape[0]), heat.index.astype(str))\nplt.title('SVM Grid CV Mean Accuracy')\nplt.xlabel('gamma')\nplt.ylabel('C')\nplt.colorbar()\nplt.tight_layout()\nplt.show()\n\n# Train best on full training set and create submission\nbest_svm = svm_gs.best_estimator_\nbest_svm.fit(X_full_no_int, y_full_1d)\ntest_pred = best_svm.predict(X_test_no_int)\nsub_tuned = pd.DataFrame({'id': test['id'], 'NObeyesdad': test_pred})\nout_path = \"/kaggle/working/submission.csv\"\nsub_tuned.to_csv(out_path, index=False)\nprint(\"Saved:\", out_path)\n\n# (Optional) register in your models dict for later reuse\nmodels['svm_rbf_tuned'] = best_svm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T03:03:11.107902Z","iopub.status.idle":"2025-09-03T03:03:11.108290Z","shell.execute_reply.started":"2025-09-03T03:03:11.108125Z","shell.execute_reply":"2025-09-03T03:03:11.108143Z"}},"outputs":[],"execution_count":null}]}